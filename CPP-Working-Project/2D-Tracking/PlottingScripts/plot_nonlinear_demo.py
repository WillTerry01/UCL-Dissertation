#!/usr/bin/env python3
"""
Visualization script for nonlinear tracking demonstration results.
Reads HDF5 files generated by demo_nonlinear_tracking.cpp and creates plots.
"""

import h5py
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.gridspec import GridSpec
import os

def load_nonlinear_demo_results(filename):
    """Load nonlinear demonstration results from HDF5 file."""
    print(f"Loading nonlinear results from: {filename}")
    
    if not os.path.exists(filename):
        print(f"Error: File {filename} not found!")
        print("Please run './demo_nonlinear_tracking' first to generate the data.")
        return None
    
    try:
        with h5py.File(filename, 'r') as f:
            # Load datasets
            true_states = np.array(f['true_states'])
            estimated_states = np.array(f['estimates'])  # Fixed: was 'estimated_states'
            measurements = np.array(f['measurements'])
            chi2_values = np.array(f['chi2_values'])
            consistency_metrics = np.array(f['consistency_metrics'])
            
            print(f"Loaded {true_states.shape[0]} nonlinear trajectories, each with {true_states.shape[1]} time steps")
            print(f"Chi² range: {np.min(chi2_values):.2f} to {np.max(chi2_values):.2f}")
            print(f"Consistency metrics range: {np.min(consistency_metrics):.3f} to {np.max(consistency_metrics):.3f}")
            
            return {
                'true_states': true_states,
                'estimated_states': estimated_states,
                'measurements': measurements,
                'chi2_values': chi2_values,
                'consistency_metrics': consistency_metrics
            }
    except Exception as e:
        print(f"Error loading file: {e}")
        return None

def plot_nonlinear_trajectory_comparison(data, run_idx=0):
    """Plot nonlinear trajectory comparison for a specific run."""
    true_pos = data['true_states'][run_idx, :, :2]  # [x, y] positions
    est_pos = data['estimated_states'][run_idx, :, :2]
    measurements = data['measurements'][run_idx, :, :2]
    chi2 = data['chi2_values'][run_idx]
    consistency = data['consistency_metrics'][run_idx]
    
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    # Plot 1: Trajectory paths (nonlinear - curved)
    ax1 = axes[0]
    ax1.plot(true_pos[:, 0], true_pos[:, 1], 'g-', linewidth=2, label='True Trajectory', alpha=0.8)
    ax1.plot(est_pos[:, 0], est_pos[:, 1], 'b--', linewidth=2, label='Estimated Trajectory', alpha=0.8)
    ax1.scatter(measurements[:, 0], measurements[:, 1], c='red', s=20, alpha=0.6, label='GPS Measurements', zorder=5)
    
    # Mark start and end points
    ax1.scatter(true_pos[0, 0], true_pos[0, 1], c='green', s=100, marker='s', label='Start (True)', zorder=10)
    ax1.scatter(true_pos[-1, 0], true_pos[-1, 1], c='green', s=100, marker='^', label='End (True)', zorder=10)
    ax1.scatter(est_pos[0, 0], est_pos[0, 1], c='blue', s=80, marker='o', label='Start (Est)', zorder=10)
    ax1.scatter(est_pos[-1, 0], est_pos[-1, 1], c='blue', s=80, marker='D', label='End (Est)', zorder=10)
    
    ax1.set_xlabel('X Position (m)')
    ax1.set_ylabel('Y Position (m)')
    ax1.set_title(f'Nonlinear Trajectory Comparison (Run {run_idx+1})\n' + 
                  f'Chi² = {chi2:.2f}, Consistency = {consistency:.3f}')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.axis('equal')
    
    # Plot 2: Position error over time
    ax2 = axes[1]
    time_steps = np.arange(len(true_pos)) * 0.1  # Assuming dt = 0.1s
    pos_errors = np.linalg.norm(true_pos - est_pos, axis=1)
    
    ax2.plot(time_steps, pos_errors, 'r-', linewidth=2, label='Position Error')
    ax2.fill_between(time_steps, 0, pos_errors, alpha=0.3, color='red')
    
    mean_error = np.mean(pos_errors)
    ax2.axhline(y=mean_error, color='orange', linestyle='--', linewidth=2, 
                label=f'Mean Error = {mean_error:.3f} m')
    
    ax2.set_xlabel('Time (s)')
    ax2.set_ylabel('Position Error (m)')
    ax2.set_title('Position Error Over Time')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def plot_nonlinear_velocity_comparison(data, run_idx=0):
    """Plot nonlinear velocity comparison for a specific run."""
    true_vel = data['true_states'][run_idx, :, 2:]  # [vx, vy] velocities
    est_vel = data['estimated_states'][run_idx, :, 2:]
    time_steps = np.arange(len(true_vel)) * 0.1  # Assuming dt = 0.1s
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # X velocity
    axes[0, 0].plot(time_steps, true_vel[:, 0], 'g-', linewidth=2, label='True Vx')
    axes[0, 0].plot(time_steps, est_vel[:, 0], 'b--', linewidth=2, label='Estimated Vx')
    axes[0, 0].set_xlabel('Time (s)')
    axes[0, 0].set_ylabel('X Velocity (m/s)')
    axes[0, 0].set_title('X Velocity Comparison')
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # Y velocity
    axes[0, 1].plot(time_steps, true_vel[:, 1], 'g-', linewidth=2, label='True Vy')
    axes[0, 1].plot(time_steps, est_vel[:, 1], 'b--', linewidth=2, label='Estimated Vy')
    axes[0, 1].set_xlabel('Time (s)')
    axes[0, 1].set_ylabel('Y Velocity (m/s)')
    axes[0, 1].set_title('Y Velocity Comparison')
    axes[0, 1].legend()
    axes[0, 1].grid(True, alpha=0.3)
    
    # Velocity errors
    vel_errors = np.linalg.norm(true_vel - est_vel, axis=1)
    axes[1, 0].plot(time_steps, vel_errors, 'r-', linewidth=2)
    axes[1, 0].fill_between(time_steps, 0, vel_errors, alpha=0.3, color='red')
    mean_vel_error = np.mean(vel_errors)
    axes[1, 0].axhline(y=mean_vel_error, color='orange', linestyle='--', 
                       label=f'Mean = {mean_vel_error:.3f} m/s')
    axes[1, 0].set_xlabel('Time (s)')
    axes[1, 0].set_ylabel('Velocity Error (m/s)')
    axes[1, 0].set_title('Velocity Error Over Time')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # Velocity components error
    vx_error = np.abs(true_vel[:, 0] - est_vel[:, 0])
    vy_error = np.abs(true_vel[:, 1] - est_vel[:, 1])
    axes[1, 1].plot(time_steps, vx_error, 'b-', linewidth=2, label='|Vx Error|')
    axes[1, 1].plot(time_steps, vy_error, 'r-', linewidth=2, label='|Vy Error|')
    axes[1, 1].set_xlabel('Time (s)')
    axes[1, 1].set_ylabel('Velocity Component Error (m/s)')
    axes[1, 1].set_title('Velocity Component Errors')
    axes[1, 1].legend()
    axes[1, 1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def plot_nonlinear_summary_statistics(data):
    """Plot summary statistics across all nonlinear runs."""
    num_runs, num_steps, _ = data['true_states'].shape
    
    # Calculate statistics for each run
    pos_errors_all = []
    vel_errors_all = []
    final_pos_errors = []
    
    for run in range(num_runs):
        true_pos = data['true_states'][run, :, :2]
        est_pos = data['estimated_states'][run, :, :2]
        true_vel = data['true_states'][run, :, 2:]
        est_vel = data['estimated_states'][run, :, 2:]
        
        pos_errors = np.linalg.norm(true_pos - est_pos, axis=1)
        vel_errors = np.linalg.norm(true_vel - est_vel, axis=1)
        
        pos_errors_all.append(pos_errors)
        vel_errors_all.append(vel_errors)
        final_pos_errors.append(pos_errors[-1])
    
    pos_errors_all = np.array(pos_errors_all)
    vel_errors_all = np.array(vel_errors_all)
    
    fig = plt.figure(figsize=(16, 12))
    gs = GridSpec(3, 2, figure=fig)
    
    # Plot 1: Position errors over time (all runs)
    ax1 = fig.add_subplot(gs[0, :])
    time_steps = np.arange(num_steps) * 0.1  # Assuming dt = 0.1s
    
    for run in range(num_runs):
        ax1.plot(time_steps, pos_errors_all[run], alpha=0.6, linewidth=1)
    
    mean_pos_errors = np.mean(pos_errors_all, axis=0)
    std_pos_errors = np.std(pos_errors_all, axis=0)
    ax1.plot(time_steps, mean_pos_errors, 'k-', linewidth=3, label='Mean')
    ax1.fill_between(time_steps, 
                     mean_pos_errors - std_pos_errors,
                     mean_pos_errors + std_pos_errors,
                     alpha=0.3, color='gray', label='±1σ')
    
    ax1.set_xlabel('Time (s)')
    ax1.set_ylabel('Position Error (m)')
    ax1.set_title(f'Position Errors Across {num_runs} Nonlinear Runs')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Chi-squared values
    ax2 = fig.add_subplot(gs[1, 0])
    runs = np.arange(1, num_runs + 1)
    bars = ax2.bar(runs, data['chi2_values'], alpha=0.7, color='skyblue', edgecolor='navy')
    ax2.axhline(y=np.mean(data['chi2_values']), color='red', linestyle='--', 
                linewidth=2, label=f'Mean = {np.mean(data["chi2_values"]):.2f}')
    ax2.set_xlabel('Run Number')
    ax2.set_ylabel('Chi-squared Value')
    ax2.set_title('Chi-squared Values by Run')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Plot 3: Consistency metrics
    ax3 = fig.add_subplot(gs[1, 1])
    ax3.bar(runs, data['consistency_metrics'], alpha=0.7, color='lightcoral', edgecolor='darkred')
    ax3.axhline(y=1.0, color='green', linestyle='-', linewidth=2, 
                label='Optimal = 1.0', alpha=0.7)
    ax3.axhline(y=np.mean(data['consistency_metrics']), color='blue', linestyle='--', 
                linewidth=2, label=f'Mean = {np.mean(data["consistency_metrics"]):.3f}')
    ax3.set_xlabel('Run Number')
    ax3.set_ylabel('Consistency Metric')
    ax3.set_title('Consistency Metrics by Run\n(≈1.0 = Optimal Parameters)')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # Plot 4: Error distribution histogram
    ax4 = fig.add_subplot(gs[2, :])
    all_pos_errors = pos_errors_all.flatten()
    ax4.hist(all_pos_errors, bins=50, alpha=0.7, color='lightgreen', edgecolor='darkgreen')
    ax4.axvline(x=np.mean(all_pos_errors), color='red', linestyle='--', 
                linewidth=2, label=f'Mean = {np.mean(all_pos_errors):.3f} m')
    ax4.axvline(x=np.median(all_pos_errors), color='blue', linestyle='--', 
                linewidth=2, label=f'Median = {np.median(all_pos_errors):.3f} m')
    ax4.set_xlabel('Position Error (m)')
    ax4.set_ylabel('Frequency')
    ax4.set_title('Distribution of All Position Errors')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def plot_consistency_analysis(data):
    """Plot detailed consistency analysis."""
    num_runs = len(data['consistency_metrics'])
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # Plot 1: Consistency vs Chi-squared scatter
    ax1 = axes[0, 0]
    scatter = ax1.scatter(data['chi2_values'], data['consistency_metrics'], 
                          c=range(num_runs), cmap='viridis', s=100, alpha=0.7)
    ax1.axhline(y=1.0, color='green', linestyle='-', linewidth=2, 
                label='Optimal Consistency = 1.0', alpha=0.7)
    ax1.set_xlabel('Chi-squared Value')
    ax1.set_ylabel('Consistency Metric')
    ax1.set_title('Consistency vs Chi-squared\n(Optimal: Consistency ≈ 1.0)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    plt.colorbar(scatter, ax=ax1, label='Run Number')
    
    # Plot 2: Consistency metric distribution
    ax2 = axes[0, 1]
    ax2.hist(data['consistency_metrics'], bins=min(10, num_runs), 
              alpha=0.7, color='lightblue', edgecolor='navy')
    ax2.axvline(x=1.0, color='green', linestyle='-', linewidth=2, 
                label='Optimal = 1.0', alpha=0.7)
    ax2.axvline(x=np.mean(data['consistency_metrics']), color='red', linestyle='--', 
                linewidth=2, label=f'Mean = {np.mean(data["consistency_metrics"]):.3f}')
    ax2.set_xlabel('Consistency Metric')
    ax2.set_ylabel('Frequency')
    ax2.set_title('Distribution of Consistency Metrics')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # Plot 3: Run-by-run performance
    ax3 = axes[1, 0]
    runs = np.arange(1, num_runs + 1)
    ax3_twin = ax3.twinx()
    
    line1 = ax3.plot(runs, data['chi2_values'], 'b-o', linewidth=2, label='Chi-squared')
    line2 = ax3_twin.plot(runs, data['consistency_metrics'], 'r-s', linewidth=2, label='Consistency')
    
    ax3.set_xlabel('Run Number')
    ax3.set_ylabel('Chi-squared Value', color='blue')
    ax3_twin.set_ylabel('Consistency Metric', color='red')
    ax3.set_title('Performance Metrics by Run')
    
    # Combine legends
    lines = line1 + line2
    labels = [l.get_label() for l in lines]
    ax3.legend(lines, labels, loc='upper left')
    ax3.grid(True, alpha=0.3)
    
    # Plot 4: Parameter quality assessment
    ax4 = axes[1, 1]
    consistency = data['consistency_metrics']
    
    # Categorize parameter quality
    optimal = np.sum(np.abs(consistency - 1.0) < 0.2)
    aggressive = np.sum(consistency > 1.2)
    conservative = np.sum(consistency < 0.8)
    
    categories = ['Optimal\n(0.8-1.2)', 'Too Aggressive\n(>1.2)', 'Too Conservative\n(<0.8)']
    counts = [optimal, aggressive, conservative]
    colors = ['green', 'red', 'orange']
    
    bars = ax4.bar(categories, counts, color=colors, alpha=0.7, edgecolor='black')
    ax4.set_ylabel('Number of Runs')
    ax4.set_title('Parameter Quality Assessment\nBased on Consistency Metrics')
    ax4.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar, count in zip(bars, counts):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{count}', ha='center', va='bottom')
    
    plt.tight_layout()
    return fig

def main():
    """Main function to generate all nonlinear plots."""
    print("=== Nonlinear Tracking Visualization ===")
    
    # Load data
    data_file = "../2D-Tracking/Saved_Data/nonlinear_tracking_results.h5"
    data = load_nonlinear_demo_results(data_file)
    
    if data is None:
        return
    
    print(f"\nGenerating plots for {data['true_states'].shape[0]} nonlinear trajectories...")
    
    # Create output directory for plots - use absolute path from script location
    plots_dir = os.path.join(os.path.dirname(__file__), "..", "plots")
    os.makedirs(plots_dir, exist_ok=True)
    print(f"Plots will be saved to: {plots_dir}")
    
    # Plot 1: Trajectory comparison for first run
    print("Creating nonlinear trajectory comparison plot...")
    fig1 = plot_nonlinear_trajectory_comparison(data, run_idx=0)
    fig1.savefig(os.path.join(plots_dir, "nonlinear_trajectory_comparison.png"), dpi=300, bbox_inches='tight')
    plt.close(fig1)
    
    # Plot 2: Velocity comparison for first run
    print("Creating nonlinear velocity comparison plot...")
    fig2 = plot_nonlinear_velocity_comparison(data, run_idx=0)
    fig2.savefig(os.path.join(plots_dir, "nonlinear_velocity_comparison.png"), dpi=300, bbox_inches='tight')
    plt.close(fig2)
    
    # Plot 3: Summary statistics
    print("Creating nonlinear summary statistics plot...")
    fig3 = plot_nonlinear_summary_statistics(data)
    fig3.savefig(os.path.join(plots_dir, "nonlinear_summary_statistics.png"), dpi=300, bbox_inches='tight')
    plt.close(fig3)
    
    # Plot 4: Consistency analysis
    print("Creating consistency analysis plot...")
    fig4 = plot_consistency_analysis(data)
    fig4.savefig(os.path.join(plots_dir, "nonlinear_consistency_analysis.png"), dpi=300, bbox_inches='tight')
    plt.close(fig4)
    
    # Generate additional trajectory comparisons for multiple runs
    num_runs = min(3, data['true_states'].shape[0])
    for run_idx in range(num_runs):
        print(f"Creating nonlinear trajectory plot for run {run_idx + 1}...")
        fig = plot_nonlinear_trajectory_comparison(data, run_idx=run_idx)
        fig.savefig(os.path.join(plots_dir, f"nonlinear_trajectory_run_{run_idx+1}.png"), dpi=300, bbox_inches='tight')
        plt.close(fig)
    
    print("\n=== Nonlinear Plotting Complete ===")
    print(f"Generated plots saved in: {plots_dir}")
    print("  - nonlinear_trajectory_comparison.png: Main trajectory comparison")
    print("  - nonlinear_velocity_comparison.png: Velocity analysis")
    print("  - nonlinear_summary_statistics.png: Overall performance statistics")
    print("  - nonlinear_consistency_analysis.png: Consistency metric analysis")
    print(f"  - nonlinear_trajectory_run_*.png: Individual run comparisons")
    
    print("\nSummary of nonlinear tracking performance:")
    print(f"  Number of runs: {len(data['chi2_values'])}")
    print(f"  Average chi-squared: {np.mean(data['chi2_values']):.2f}")
    print(f"  Average consistency metric: {np.mean(data['consistency_metrics']):.3f}")
    print(f"  Consistency metric range: {np.min(data['consistency_metrics']):.3f} to {np.max(data['consistency_metrics']):.3f}")
    
    # Parameter quality assessment
    consistency = data['consistency_metrics']
    optimal_count = np.sum(np.abs(consistency - 1.0) < 0.2)
    print(f"  Runs with optimal parameters (consistency ≈ 1.0): {optimal_count}/{len(consistency)}")

if __name__ == "__main__":
    main() 